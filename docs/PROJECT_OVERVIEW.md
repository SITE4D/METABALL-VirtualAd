# プロジェクト概要

## プロジェクト名
**METABALL Virtual Ad** - バーチャル広告生成システム

## 目的
野球中継のバックネット裏にリアルタイムでバーチャル広告を挿入するシステムを開発する。Viz Arenaのようなプロフェッショナル品質の映像処理を、より柔軟で拡張可能な形で実現する。

## 背景

### 市場ニーズ
- スポーツ放送における広告収益の最大化
- 物理的な広告スペースの制限を超えた収益機会
- 地域・視聴者層に応じた広告のカスタマイズ

### 競合製品
**Viz Arena** (Vizrt社)
- AI アシストキャリブレーション
- AI キーヤー
- AI アドバンスドカットディテクション

本プロジェクトでは、単一カメラに特化することで、以下を実現：
- よりシンプルな運用（カットディテクション不要）
- 特定スタジアムに最適化されたAIモデル
- コスト効率の高いシステム

## ゴール

### 短期目標（Phase 0-5完了時）
1. ✅ 60fpsリアルタイム処理の達成
2. ✅ 高精度なカメラトラッキング（画角変化・移動対応）
3. ✅ 自然なキーイング（選手が広告の前に表示）
4. ✅ ファイルモードでの検証機能
5. ✅ AI学習パイプラインの確立

### 長期目標
1. 複数カメラ対応
2. 他のスポーツへの展開（サッカー、バスケットボール等）
3. クラウドベースの学習データ共有
4. リアルタイム広告配信プラットフォーム統合

## 主要機能

### 1. AIアシストキャリブレーション（必須）
**目的**: カメラ映像のみから高精度なカメラパラメータを推定

**技術要素**:
- 特徴点検出（ORB/AKAZE）
- ホモグラフィ推定
- PnPソルバー
- ディープラーニングベースの補正

**入力**: カメラ映像（1920x1080 @ 60fps）
**出力**: カメラ行列、回転ベクトル、平行移動ベクトル

**成功基準**:
- トラッキング精度: 2ピクセル以内の誤差
- 画角変化への対応: ±10度
- カメラ移動への追従: 遅延3フレーム以内

### 2. AIキーヤー（優先度高）
**目的**: 選手と広告を自然に合成（デプスベースコンポジット）

**技術要素**:
- セグメンテーション（DeepLabV3+）
- デプス推定（MiDaS Small）
- リアルタイム合成

**入力**: カメラ映像 + カメラパラメータ
**出力**: 合成映像（選手が広告の前）

**成功基準**:
- セグメンテーション精度: IoU > 0.90
- エッジの自然さ: 目視で違和感なし
- 処理時間: 8ms/frame以内

### 3. ライブ/ファイルモード切り替え
**目的**: 開発・検証の効率化とAI学習データ収集

**ライブモード**:
- HDMIキャプチャデバイスから入力
- リアルタイム60fps処理
- HDMI出力

**ファイルモード**:
- サンプル映像ファイルを入力
- リアルタイム処理シミュレーション
- フレーム単位での巻き戻し・一時停止
- 学習データアノテーション

**成功基準**:
- モード切り替え: 1秒以内
- ファイル再生: 正確な60fps維持
- アノテーション効率: 100サンプル/時間

### 4. データ収集・学習パイプライン
**目的**: AI精度の継続的改善

**機能**:
- インタラクティブアノテーションツール
- 学習データ管理（JSON + 画像）
- 自動学習スクリプト
- ONNX/TensorRT変換

**ワークフロー**:
```
サンプル映像 → アノテーション → 学習データ → モデル訓練 → ONNX変換 → 統合
```

## ユースケース

### 主要ユースケース: 野球中継のバックネット広告

**シナリオ**:
1. ピッチャー背面カメラ（バックネット裏を表示）
2. 打者ごとに画角が多少変化
3. ピッチャーゴロなどでカメラが移動
4. 審判・捕手・打者が広告の前を横切る

**要件**:
- バックネット平面にバーチャル広告を配置
- 画角変化に追従
- カメラ移動時も広告位置を維持
- 選手・審判が広告の前に正しく表示

**期待される結果**:
- 視聴者が違和感なく広告を認識
- 広告の視認時間: 平均30秒/打席
- 追加収益: 既存広告枠の150%

### サブユースケース: オフライン処理

**シナリオ**:
1. 録画済み試合映像を入力
2. ファイルモードで処理
3. 異なる広告パターンを複数生成
4. 地域別に出力

**要件**:
- リアルタイム性は不要
- 高画質優先
- バッチ処理対応

## 技術的制約

### 必須制約
1. **60fps処理**: 16.67ms/frame以内
2. **Windows専用**: DirectX 12 / CUDA必須
3. **NVIDIA GPU**: TensorRT最適化必須
4. **単一カメラ**: マルチカメラは対象外

### 推奨制約
1. **解像度**: 1920x1080（フルHD）
2. **メモリ**: 16GB以上
3. **ストレージ**: SSD推奨

### 将来的な制約緩和
1. Mac対応（Phase 2以降）
2. 4K対応（GPU性能向上後）
3. マルチカメラ対応

## 開発アプローチ

### 段階的開発
1. **Phase 0-1**: 基盤構築（映像I/O）
2. **Phase 1.5**: データ収集ツール
3. **Phase 2-3**: AIコア機能（トラッキング・キーヤー）
4. **Phase 4**: レンダリング
5. **Phase 5**: 統合・最適化

### アジャイル手法
- 2週間スプリント
- 各Phase終了時にデモ
- 継続的なフィードバック

### 品質保証
- Phase毎の成功基準チェック
- サンプル映像での検証
- 性能プロファイリング（60fps確認）

## 成功指標

### 技術指標
- ✅ 60fps達成率: 95%以上
- ✅ トラッキング精度: 2px以内
- ✅ セグメンテーション精度: IoU > 0.90
- ✅ CPU使用率: 30%以下
- ✅ GPU使用率: 70-80%

### 運用指標
- データ収集効率: 100サンプル/時間
- モデル学習時間: 2時間以内
- システム起動時間: 10秒以内

### ビジネス指標（将来）
- 広告視認時間
- ROI（投資対効果）
- 運用コスト削減率

## リスクと対策

### 技術リスク

| リスク | 影響 | 対策 |
|--------|------|------|
| 60fps未達成 | 高 | 段階的最適化、TensorRT活用 |
| トラッキング精度不足 | 高 | 学習データ拡充、モデル改善 |
| キーイング品質低下 | 中 | 高精度モデル、エッジリファインメント |
| GPU互換性問題 | 中 | NVIDIA専用に限定 |

### 運用リスク

| リスク | 影響 | 対策 |
|--------|------|------|
| ハードウェア故障 | 高 | 冗長構成、予備機 |
| 学習データ不足 | 中 | 継続的なデータ収集 |
| 照明変化への非対応 | 低 | データ拡張、再学習 |

## チーム構成（想定）

- **開発者**: 1-2名（C++ + Python）
- **AI/MLエンジニア**: 1名（モデル訓練）
- **QAエンジニア**: 1名（検証）

## スケジュール

- **Phase 0-5**: 4-6週間
- **検証・改善**: 1-2週間
- **本番運用開始**: 6-8週間後

## 次のステップ

1. ✅ ドキュメント作成完了
2. → Windows環境セットアップ
3. → Phase 0: 環境構築
4. → Phase 1: 映像I/O実装

詳細は [IMPLEMENTATION_PLAN.md](IMPLEMENTATION_PLAN.md) を参照。
